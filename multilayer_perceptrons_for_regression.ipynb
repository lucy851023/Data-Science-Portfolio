{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptrons for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from mxnet import gluon,init,autograd,np,nd,npx,gpu\n",
    "from mxnet.metric import RMSE\n",
    "from mxnet.gluon import nn\n",
    "#import d2l\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (463715, 90)\n",
      "y_train (463715,)\n",
      "x_test (51630, 90)\n",
      "y_test (51630,)\n"
     ]
    }
   ],
   "source": [
    "file = open('msd_full.pickle','rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "print('x_train',data['X_train'].shape)\n",
    "print('y_train',data['Y_train'].shape)\n",
    "print('x_test',data['X_test'].shape)\n",
    "print('y_test',data['Y_test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize all numerical features in the training set before splitting into subtraining and validation. Apply the mean and standard deviation of features in the training set to standardize numerical features in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all feature \n",
    "xscaler = StandardScaler().fit(data['X_train'])\n",
    "x_train = xscaler.transform(data['X_train'])\n",
    "x_test = xscaler.transform(data['X_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserve the last 10% of the training dataset as the validation set, and the remaining 90% as the subtraining set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417343\n",
      "x_subtrain:  (417343, 90)\n",
      "Y_subtrain:  (417343,)\n",
      "x_val: (46372, 90)\n",
      "y_val: (46372,)\n"
     ]
    }
   ],
   "source": [
    "# prepare data that we need\n",
    "sub_ind = int(x_train.shape[0] * 0.9)\n",
    "print(sub_ind)\n",
    "\n",
    "y_train = data['Y_train']\n",
    "y_test = data['Y_test']\n",
    "mean_val = y_train.mean()\n",
    "y_train_demean = y_train - mean_val\n",
    "y_test_demean = y_test - mean_val\n",
    "x_subtrain = x_train[0:sub_ind]\n",
    "x_val = x_train[sub_ind:]\n",
    "y_subtrain = y_train[0:sub_ind]\n",
    "y_val = y_train[sub_ind:]\n",
    "y_subtrain_demean = y_train_demean[0:sub_ind]\n",
    "y_val_demean = y_train_demean[sub_ind:]\n",
    "print('x_subtrain: ',x_subtrain.shape)\n",
    "print('Y_subtrain: ',y_subtrain.shape)\n",
    "print('x_val:',x_val.shape)\n",
    "print('y_val:',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (90%):\n",
    "Train and tune the models listed above. Report test RMSE for each model setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS\n",
    "We don't need to tune hyperparameter when using standard OLS model, so we just use validation set and test set to compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data:  9.574683375081593\n",
      "RMSE for test data:  9.550724957519298\n"
     ]
    }
   ],
   "source": [
    "m1 = LinearRegression()\n",
    "m1.fit(x_subtrain[:10000],y_subtrain[:10000])\n",
    "y_pred1 = m1.predict(x_val)\n",
    "y_pred2 = m1.predict(x_test)\n",
    "rms1 = sqrt(mean_squared_error(y_val,y_pred1))\n",
    "rms2 = sqrt(mean_squared_error(y_test,y_pred2))\n",
    "print('RMSE for validation data: ',rms1)\n",
    "print('RMSE for test data: ',rms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_0_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a Gluon data loader\"\"\"\n",
    "    dataset = gluon.data.ArrayDataset(*data_arrays)\n",
    "    return gluon.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def train_model(net,x_train,y_train,x_val,y_val,loss, trainer,num_epochs=3000,batch_size=32,early_stop=True):\n",
    "    \n",
    "    features = np.array(x_train.astype('float32'),ctx=gpu())\n",
    "    target = np.array(y_train.astype('float32'),ctx=gpu())\n",
    "    train_iter = load_array((features, target), batch_size)\n",
    "    \n",
    "    val_features = np.array(x_val.astype('float32'),ctx=gpu())\n",
    "    val_target = np.array(y_val.astype('float32'),ctx=gpu())\n",
    "    \n",
    "    #net.load_parameters('net.params', ctx=gpu(0))\n",
    "    \n",
    "    pre_rmse=0.0\n",
    "    count=0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for X, y in train_iter:\n",
    "            X = X.as_in_context(gpu())\n",
    "            y = y.as_in_context(gpu())\n",
    "            with autograd.record():\n",
    "                l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "    \n",
    "\n",
    "        l = loss(net(features), target)\n",
    "        val_rmse = RMSE()\n",
    "        val_rmse.update(val_target,net(val_features))\n",
    "        \n",
    "        if epoch ==1:\n",
    "            pre_rmse=val_rmse.get()[1]\n",
    "            \n",
    "        if epoch % 10 ==0:\n",
    "            print('epoch %d, training loss: %f , validation RMSE: %f' % (epoch, l.mean().asnumpy(),val_rmse.get()[1]))\n",
    "            \n",
    "        if epoch % 50 == 0 :\n",
    "\n",
    "            if val_rmse.get()[1] - pre_rmse >= 0 and early_stop==True:\n",
    "                print('------Early Stop------')\n",
    "                break\n",
    "            else:\n",
    "                pre_rmse = val_rmse.get()[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #pre_rmse = val_rmse.get()[1]\n",
    "    \n",
    "    print('finish training... End at Epoch ',epoch)\n",
    "            \n",
    "\n",
    "def evaluate_RMSE(model,x_test,y_test):\n",
    "    test_target = np.array(y_test.astype('float32'),ctx=gpu())\n",
    "    test_features = np.array(x_test.astype('float32'),ctx=gpu())\n",
    "    test_rmse = RMSE()\n",
    "    test_rmse.update(test_target,model(test_features))\n",
    "    print('Test RMSE:',test_rmse.get()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 16,32,64 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 46.175613 , validation RMSE: 9.598289\n",
      "epoch 20, training loss: 45.868320 , validation RMSE: 9.575791\n",
      "epoch 30, training loss: 45.875324 , validation RMSE: 9.585664\n",
      "epoch 40, training loss: 45.808174 , validation RMSE: 9.572514\n",
      "epoch 50, training loss: 45.862011 , validation RMSE: 9.585183\n",
      "epoch 60, training loss: 45.799294 , validation RMSE: 9.578393\n",
      "epoch 70, training loss: 45.800877 , validation RMSE: 9.571258\n",
      "epoch 80, training loss: 45.801388 , validation RMSE: 9.580872\n",
      "epoch 90, training loss: 45.808609 , validation RMSE: 9.580564\n",
      "epoch 100, training loss: 45.811005 , validation RMSE: 9.583174\n",
      "epoch 110, training loss: 45.788792 , validation RMSE: 9.580637\n",
      "epoch 120, training loss: 45.875565 , validation RMSE: 9.580915\n",
      "epoch 130, training loss: 45.820789 , validation RMSE: 9.577175\n",
      "epoch 140, training loss: 45.830688 , validation RMSE: 9.582801\n",
      "epoch 150, training loss: 45.812447 , validation RMSE: 9.585162\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "#train model - batch size = 16\n",
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,\n",
    "            loss,trainer,num_epochs,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 47.034111 , validation RMSE: 9.686528\n",
      "epoch 20, training loss: 46.155087 , validation RMSE: 9.599195\n",
      "epoch 30, training loss: 45.954365 , validation RMSE: 9.588474\n",
      "epoch 40, training loss: 45.864407 , validation RMSE: 9.572903\n",
      "epoch 50, training loss: 45.833149 , validation RMSE: 9.572663\n",
      "epoch 60, training loss: 45.821266 , validation RMSE: 9.568368\n",
      "epoch 70, training loss: 45.797195 , validation RMSE: 9.571445\n",
      "epoch 80, training loss: 45.807320 , validation RMSE: 9.570119\n",
      "epoch 90, training loss: 45.792061 , validation RMSE: 9.574532\n",
      "epoch 100, training loss: 45.793892 , validation RMSE: 9.569628\n",
      "epoch 110, training loss: 45.784645 , validation RMSE: 9.571787\n",
      "epoch 120, training loss: 45.797333 , validation RMSE: 9.577531\n",
      "epoch 130, training loss: 45.798561 , validation RMSE: 9.575035\n",
      "epoch 140, training loss: 45.780235 , validation RMSE: 9.573931\n",
      "epoch 150, training loss: 45.776791 , validation RMSE: 9.573990\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "#train model - batch size = 32\n",
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,\n",
    "            loss,trainer,num_epochs,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 48.632748 , validation RMSE: 9.833032\n",
      "epoch 20, training loss: 47.030479 , validation RMSE: 9.684284\n",
      "epoch 30, training loss: 46.418140 , validation RMSE: 9.626363\n",
      "epoch 40, training loss: 46.143650 , validation RMSE: 9.600238\n",
      "epoch 50, training loss: 46.007103 , validation RMSE: 9.587128\n",
      "epoch 60, training loss: 45.931751 , validation RMSE: 9.580962\n",
      "epoch 70, training loss: 45.887302 , validation RMSE: 9.576270\n",
      "epoch 80, training loss: 45.861057 , validation RMSE: 9.575994\n",
      "epoch 90, training loss: 45.838451 , validation RMSE: 9.572468\n",
      "epoch 100, training loss: 45.827129 , validation RMSE: 9.574351\n",
      "epoch 110, training loss: 45.814171 , validation RMSE: 9.571141\n",
      "epoch 120, training loss: 45.806564 , validation RMSE: 9.572041\n",
      "epoch 130, training loss: 45.800705 , validation RMSE: 9.571461\n",
      "epoch 140, training loss: 45.796036 , validation RMSE: 9.570953\n",
      "epoch 150, training loss: 45.792992 , validation RMSE: 9.571774\n",
      "epoch 160, training loss: 45.789230 , validation RMSE: 9.572248\n",
      "epoch 170, training loss: 45.786385 , validation RMSE: 9.572412\n",
      "epoch 180, training loss: 45.787251 , validation RMSE: 9.574392\n",
      "epoch 190, training loss: 45.782791 , validation RMSE: 9.572421\n",
      "epoch 200, training loss: 45.781364 , validation RMSE: 9.572557\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  200\n"
     ]
    }
   ],
   "source": [
    "#train model - batch size = 64\n",
    "# model structure\n",
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,\n",
    "            loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|16|9.5852|\n",
    "|32|9.5740|\n",
    "|64|9.5725|\n",
    "\n",
    "從實驗結果得知，batch size = 64 的 validation RMSE最低，因此選用batch size = 64作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.548772811889648\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model3,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_1_dm\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 16,32,64 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.216850 , validation RMSE: 10.864101\n",
      "epoch 20, training loss: 49.422592 , validation RMSE: 9.912361\n",
      "epoch 30, training loss: 43.689594 , validation RMSE: 9.377723\n",
      "epoch 40, training loss: 42.316460 , validation RMSE: 9.275238\n",
      "epoch 50, training loss: 41.638336 , validation RMSE: 9.239089\n",
      "epoch 60, training loss: 41.078587 , validation RMSE: 9.222880\n",
      "epoch 70, training loss: 40.589249 , validation RMSE: 9.206519\n",
      "epoch 80, training loss: 40.115952 , validation RMSE: 9.193476\n",
      "epoch 90, training loss: 39.637615 , validation RMSE: 9.184632\n",
      "epoch 100, training loss: 39.111950 , validation RMSE: 9.181135\n",
      "epoch 110, training loss: 38.572758 , validation RMSE: 9.179420\n",
      "epoch 120, training loss: 38.023556 , validation RMSE: 9.175034\n",
      "epoch 130, training loss: 37.504105 , validation RMSE: 9.187937\n",
      "epoch 140, training loss: 36.876846 , validation RMSE: 9.194909\n",
      "epoch 150, training loss: 36.310162 , validation RMSE: 9.203779\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 0.0001})\n",
    "\n",
    "#train model - batch size = 16\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.776989 , validation RMSE: 10.917001\n",
      "epoch 20, training loss: 59.443592 , validation RMSE: 10.885474\n",
      "epoch 30, training loss: 57.310349 , validation RMSE: 10.682651\n",
      "epoch 40, training loss: 51.828030 , validation RMSE: 10.150523\n",
      "epoch 50, training loss: 46.791069 , validation RMSE: 9.659284\n",
      "epoch 60, training loss: 44.252895 , validation RMSE: 9.426146\n",
      "epoch 70, training loss: 43.039055 , validation RMSE: 9.323101\n",
      "epoch 80, training loss: 42.404709 , validation RMSE: 9.276715\n",
      "epoch 90, training loss: 41.989639 , validation RMSE: 9.252031\n",
      "epoch 100, training loss: 41.637730 , validation RMSE: 9.233479\n",
      "epoch 110, training loss: 41.327396 , validation RMSE: 9.220832\n",
      "epoch 120, training loss: 41.040115 , validation RMSE: 9.210591\n",
      "epoch 130, training loss: 40.761883 , validation RMSE: 9.202125\n",
      "epoch 140, training loss: 40.475327 , validation RMSE: 9.194084\n",
      "epoch 150, training loss: 40.189880 , validation RMSE: 9.190995\n",
      "epoch 160, training loss: 39.890320 , validation RMSE: 9.184657\n",
      "epoch 170, training loss: 39.611076 , validation RMSE: 9.179697\n",
      "epoch 180, training loss: 39.343033 , validation RMSE: 9.177404\n",
      "epoch 190, training loss: 39.059578 , validation RMSE: 9.174896\n",
      "epoch 200, training loss: 38.811584 , validation RMSE: 9.175132\n",
      "epoch 210, training loss: 38.497093 , validation RMSE: 9.171776\n",
      "epoch 220, training loss: 38.213402 , validation RMSE: 9.172648\n",
      "epoch 230, training loss: 37.940273 , validation RMSE: 9.173759\n",
      "epoch 240, training loss: 37.640797 , validation RMSE: 9.176229\n",
      "epoch 250, training loss: 37.354130 , validation RMSE: 9.178051\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  250\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.0001})\n",
    "\n",
    "#train model - batch size = 32\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.808731 , validation RMSE: 10.919972\n",
      "epoch 20, training loss: 59.772148 , validation RMSE: 10.916531\n",
      "epoch 30, training loss: 59.669601 , validation RMSE: 10.906811\n",
      "epoch 40, training loss: 59.370594 , validation RMSE: 10.878314\n",
      "epoch 50, training loss: 58.544044 , validation RMSE: 10.799281\n",
      "epoch 60, training loss: 56.645508 , validation RMSE: 10.616733\n",
      "epoch 70, training loss: 53.587521 , validation RMSE: 10.319614\n",
      "epoch 80, training loss: 50.322334 , validation RMSE: 9.999773\n",
      "epoch 90, training loss: 47.722084 , validation RMSE: 9.748066\n",
      "epoch 100, training loss: 45.914349 , validation RMSE: 9.578751\n",
      "epoch 110, training loss: 44.693661 , validation RMSE: 9.469372\n",
      "epoch 120, training loss: 43.860275 , validation RMSE: 9.398204\n",
      "epoch 130, training loss: 43.282150 , validation RMSE: 9.351095\n",
      "epoch 140, training loss: 42.873138 , validation RMSE: 9.319342\n",
      "epoch 150, training loss: 42.568127 , validation RMSE: 9.296987\n",
      "epoch 160, training loss: 42.319092 , validation RMSE: 9.280579\n",
      "epoch 170, training loss: 42.107620 , validation RMSE: 9.266862\n",
      "epoch 180, training loss: 41.907795 , validation RMSE: 9.254513\n",
      "epoch 190, training loss: 41.715340 , validation RMSE: 9.242981\n",
      "epoch 200, training loss: 41.524822 , validation RMSE: 9.232889\n",
      "epoch 210, training loss: 41.351498 , validation RMSE: 9.224456\n",
      "epoch 220, training loss: 41.193119 , validation RMSE: 9.217190\n",
      "epoch 230, training loss: 41.042740 , validation RMSE: 9.211735\n",
      "epoch 240, training loss: 40.894478 , validation RMSE: 9.205940\n",
      "epoch 250, training loss: 40.751980 , validation RMSE: 9.200976\n",
      "epoch 260, training loss: 40.607800 , validation RMSE: 9.196510\n",
      "epoch 270, training loss: 40.469692 , validation RMSE: 9.192743\n",
      "epoch 280, training loss: 40.329506 , validation RMSE: 9.189858\n",
      "epoch 290, training loss: 40.193298 , validation RMSE: 9.186566\n",
      "epoch 300, training loss: 40.056370 , validation RMSE: 9.184172\n",
      "epoch 310, training loss: 39.921314 , validation RMSE: 9.181614\n",
      "epoch 320, training loss: 39.781929 , validation RMSE: 9.179610\n",
      "epoch 330, training loss: 39.643234 , validation RMSE: 9.177122\n",
      "epoch 340, training loss: 39.505981 , validation RMSE: 9.174541\n",
      "epoch 350, training loss: 39.370205 , validation RMSE: 9.173446\n",
      "epoch 360, training loss: 39.235317 , validation RMSE: 9.171836\n",
      "epoch 370, training loss: 39.099903 , validation RMSE: 9.170742\n",
      "epoch 380, training loss: 38.962994 , validation RMSE: 9.169942\n",
      "epoch 390, training loss: 38.825821 , validation RMSE: 9.168720\n",
      "epoch 400, training loss: 38.690804 , validation RMSE: 9.167959\n",
      "epoch 410, training loss: 38.555626 , validation RMSE: 9.167976\n",
      "epoch 420, training loss: 38.419117 , validation RMSE: 9.168206\n",
      "epoch 430, training loss: 38.280083 , validation RMSE: 9.168482\n",
      "epoch 440, training loss: 38.139172 , validation RMSE: 9.168232\n",
      "epoch 450, training loss: 38.000637 , validation RMSE: 9.169601\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  450\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.01),ctx=gpu())\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 0.0001})\n",
    "\n",
    "#train model - batch size = 64\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|16|9.2038|\n",
    "|32|9.1781|\n",
    "|64|9.1696|\n",
    "\n",
    "從實驗結果得知，batch size = 64 的 validation RMSE最低，因此選用batch size = 64作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.221061706542969\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model3,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_dm\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 16,32,64 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824268 , validation RMSE: 10.921429\n",
      "epoch 20, training loss: 59.824032 , validation RMSE: 10.921406\n",
      "epoch 30, training loss: 59.823673 , validation RMSE: 10.921372\n",
      "epoch 40, training loss: 59.823101 , validation RMSE: 10.921320\n",
      "epoch 50, training loss: 59.822037 , validation RMSE: 10.921222\n",
      "epoch 60, training loss: 59.819805 , validation RMSE: 10.921016\n",
      "epoch 70, training loss: 59.814243 , validation RMSE: 10.920498\n",
      "epoch 80, training loss: 59.796143 , validation RMSE: 10.918808\n",
      "epoch 90, training loss: 59.701157 , validation RMSE: 10.909915\n",
      "epoch 100, training loss: 58.197857 , validation RMSE: 10.767823\n",
      "epoch 110, training loss: 43.362961 , validation RMSE: 9.344172\n",
      "epoch 120, training loss: 40.638092 , validation RMSE: 9.162130\n",
      "epoch 130, training loss: 38.922829 , validation RMSE: 9.112578\n",
      "epoch 140, training loss: 37.089420 , validation RMSE: 9.107737\n",
      "epoch 150, training loss: 34.848827 , validation RMSE: 9.134316\n",
      "epoch 160, training loss: 32.489918 , validation RMSE: 9.227412\n",
      "epoch 170, training loss: 30.186796 , validation RMSE: 9.320636\n",
      "epoch 180, training loss: 28.035538 , validation RMSE: 9.502390\n",
      "epoch 190, training loss: 25.778065 , validation RMSE: 9.696440\n",
      "epoch 200, training loss: 24.143215 , validation RMSE: 9.920745\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  200\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.01))\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 1e-4})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824219 , validation RMSE: 10.921427\n",
      "epoch 20, training loss: 59.824001 , validation RMSE: 10.921406\n",
      "epoch 30, training loss: 59.823761 , validation RMSE: 10.921386\n",
      "epoch 40, training loss: 59.823483 , validation RMSE: 10.921359\n",
      "epoch 50, training loss: 59.823112 , validation RMSE: 10.921327\n",
      "epoch 60, training loss: 59.822620 , validation RMSE: 10.921282\n",
      "epoch 70, training loss: 59.821945 , validation RMSE: 10.921221\n",
      "epoch 80, training loss: 59.820969 , validation RMSE: 10.921131\n",
      "epoch 90, training loss: 59.819481 , validation RMSE: 10.920996\n",
      "epoch 100, training loss: 59.817123 , validation RMSE: 10.920780\n",
      "epoch 110, training loss: 59.813148 , validation RMSE: 10.920414\n",
      "epoch 120, training loss: 59.805912 , validation RMSE: 10.919744\n",
      "epoch 130, training loss: 59.791374 , validation RMSE: 10.918396\n",
      "epoch 140, training loss: 59.757931 , validation RMSE: 10.915284\n",
      "epoch 150, training loss: 59.664101 , validation RMSE: 10.906515\n",
      "epoch 160, training loss: 59.301357 , validation RMSE: 10.872457\n",
      "epoch 170, training loss: 56.982788 , validation RMSE: 10.652040\n",
      "epoch 180, training loss: 46.981434 , validation RMSE: 9.669217\n",
      "epoch 190, training loss: 42.590240 , validation RMSE: 9.278551\n",
      "epoch 200, training loss: 41.222198 , validation RMSE: 9.183377\n",
      "epoch 210, training loss: 40.307758 , validation RMSE: 9.144300\n",
      "epoch 220, training loss: 39.429394 , validation RMSE: 9.121666\n",
      "epoch 230, training loss: 38.465546 , validation RMSE: 9.111906\n",
      "epoch 240, training loss: 37.472076 , validation RMSE: 9.097013\n",
      "epoch 250, training loss: 36.421055 , validation RMSE: 9.101178\n",
      "epoch 260, training loss: 35.215717 , validation RMSE: 9.106672\n",
      "epoch 270, training loss: 34.038055 , validation RMSE: 9.149400\n",
      "epoch 280, training loss: 32.660248 , validation RMSE: 9.185809\n",
      "epoch 290, training loss: 31.377628 , validation RMSE: 9.255065\n",
      "epoch 300, training loss: 29.948973 , validation RMSE: 9.339194\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  300\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 1e-4})\n",
    "\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824131 , validation RMSE: 10.921416\n",
      "epoch 20, training loss: 59.824005 , validation RMSE: 10.921405\n",
      "epoch 30, training loss: 59.823883 , validation RMSE: 10.921392\n",
      "epoch 40, training loss: 59.823757 , validation RMSE: 10.921380\n",
      "epoch 50, training loss: 59.823620 , validation RMSE: 10.921367\n",
      "epoch 60, training loss: 59.823475 , validation RMSE: 10.921353\n",
      "epoch 70, training loss: 59.823311 , validation RMSE: 10.921337\n",
      "epoch 80, training loss: 59.823124 , validation RMSE: 10.921320\n",
      "epoch 90, training loss: 59.822918 , validation RMSE: 10.921299\n",
      "epoch 100, training loss: 59.822674 , validation RMSE: 10.921276\n",
      "epoch 110, training loss: 59.822388 , validation RMSE: 10.921249\n",
      "epoch 120, training loss: 59.822056 , validation RMSE: 10.921217\n",
      "epoch 130, training loss: 59.821651 , validation RMSE: 10.921179\n",
      "epoch 140, training loss: 59.821167 , validation RMSE: 10.921133\n",
      "epoch 150, training loss: 59.820576 , validation RMSE: 10.921077\n",
      "epoch 160, training loss: 59.819851 , validation RMSE: 10.921008\n",
      "epoch 170, training loss: 59.818951 , validation RMSE: 10.920922\n",
      "epoch 180, training loss: 59.817814 , validation RMSE: 10.920815\n",
      "epoch 190, training loss: 59.816349 , validation RMSE: 10.920676\n",
      "epoch 200, training loss: 59.814457 , validation RMSE: 10.920497\n",
      "epoch 210, training loss: 59.811954 , validation RMSE: 10.920259\n",
      "epoch 220, training loss: 59.808582 , validation RMSE: 10.919939\n",
      "epoch 230, training loss: 59.803925 , validation RMSE: 10.919497\n",
      "epoch 240, training loss: 59.797325 , validation RMSE: 10.918871\n",
      "epoch 250, training loss: 59.787670 , validation RMSE: 10.917955\n",
      "epoch 260, training loss: 59.772987 , validation RMSE: 10.916565\n",
      "epoch 270, training loss: 59.749607 , validation RMSE: 10.914352\n",
      "epoch 280, training loss: 59.710163 , validation RMSE: 10.910625\n",
      "epoch 290, training loss: 59.638664 , validation RMSE: 10.903877\n",
      "epoch 300, training loss: 59.497242 , validation RMSE: 10.890523\n",
      "epoch 310, training loss: 59.183693 , validation RMSE: 10.860873\n",
      "epoch 320, training loss: 58.393280 , validation RMSE: 10.785912\n",
      "epoch 330, training loss: 56.324532 , validation RMSE: 10.588292\n",
      "epoch 340, training loss: 52.364811 , validation RMSE: 10.204108\n",
      "epoch 350, training loss: 47.400959 , validation RMSE: 9.711020\n",
      "epoch 360, training loss: 44.015324 , validation RMSE: 9.391144\n",
      "epoch 370, training loss: 42.446777 , validation RMSE: 9.260760\n",
      "epoch 380, training loss: 41.683701 , validation RMSE: 9.206735\n",
      "epoch 390, training loss: 41.153477 , validation RMSE: 9.177904\n",
      "epoch 400, training loss: 40.696991 , validation RMSE: 9.156707\n",
      "epoch 410, training loss: 40.270245 , validation RMSE: 9.141211\n",
      "epoch 420, training loss: 39.851028 , validation RMSE: 9.126553\n",
      "epoch 430, training loss: 39.439049 , validation RMSE: 9.117037\n",
      "epoch 440, training loss: 38.975533 , validation RMSE: 9.106662\n",
      "epoch 450, training loss: 38.503914 , validation RMSE: 9.101128\n",
      "epoch 460, training loss: 37.999371 , validation RMSE: 9.098767\n",
      "epoch 470, training loss: 37.478905 , validation RMSE: 9.095307\n",
      "epoch 480, training loss: 36.931732 , validation RMSE: 9.097417\n",
      "epoch 490, training loss: 36.373203 , validation RMSE: 9.103320\n",
      "epoch 500, training loss: 35.804337 , validation RMSE: 9.107830\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  500\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.01))\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 1e-4})\n",
    "\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|16|9.9207|\n",
    "|32|9.3392|\n",
    "|64|9.1078|\n",
    "\n",
    "從實驗結果得知，batch size = 64 的 validation RMSE最低，因此選用batch size = 64作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.177852630615234\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model3,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_dm_L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune Hyperparameter - weight decay** <br>\n",
    "try different weight decay (wd) = [1,0.1,0.01] and select the best weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824444 , validation RMSE: 10.921448\n",
      "epoch 20, training loss: 59.824413 , validation RMSE: 10.921443\n",
      "epoch 30, training loss: 59.824406 , validation RMSE: 10.921442\n",
      "epoch 40, training loss: 59.824413 , validation RMSE: 10.921442\n",
      "epoch 50, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 60, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 70, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 80, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 90, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 100, training loss: 59.824406 , validation RMSE: 10.921440\n",
      "epoch 110, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 120, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 130, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 140, training loss: 59.824406 , validation RMSE: 10.921440\n",
      "epoch 150, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.01))\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "wd = 1\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 2e-4, 'wd': wd})\n",
    "model1.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824329 , validation RMSE: 10.921434\n",
      "epoch 20, training loss: 59.824139 , validation RMSE: 10.921415\n",
      "epoch 30, training loss: 59.823982 , validation RMSE: 10.921401\n",
      "epoch 40, training loss: 59.823837 , validation RMSE: 10.921388\n",
      "epoch 50, training loss: 59.823700 , validation RMSE: 10.921374\n",
      "epoch 60, training loss: 59.823555 , validation RMSE: 10.921360\n",
      "epoch 70, training loss: 59.823395 , validation RMSE: 10.921345\n",
      "epoch 80, training loss: 59.823212 , validation RMSE: 10.921327\n",
      "epoch 90, training loss: 59.822994 , validation RMSE: 10.921307\n",
      "epoch 100, training loss: 59.822731 , validation RMSE: 10.921282\n",
      "epoch 110, training loss: 59.822399 , validation RMSE: 10.921249\n",
      "epoch 120, training loss: 59.821976 , validation RMSE: 10.921209\n",
      "epoch 130, training loss: 59.821419 , validation RMSE: 10.921157\n",
      "epoch 140, training loss: 59.820675 , validation RMSE: 10.921086\n",
      "epoch 150, training loss: 59.819645 , validation RMSE: 10.920988\n",
      "epoch 160, training loss: 59.818161 , validation RMSE: 10.920848\n",
      "epoch 170, training loss: 59.815945 , validation RMSE: 10.920639\n",
      "epoch 180, training loss: 59.812443 , validation RMSE: 10.920307\n",
      "epoch 190, training loss: 59.806530 , validation RMSE: 10.919751\n",
      "epoch 200, training loss: 59.795700 , validation RMSE: 10.918730\n",
      "epoch 210, training loss: 59.773430 , validation RMSE: 10.916634\n",
      "epoch 220, training loss: 59.719807 , validation RMSE: 10.911583\n",
      "epoch 230, training loss: 59.554932 , validation RMSE: 10.896056\n",
      "epoch 240, training loss: 58.802025 , validation RMSE: 10.824917\n",
      "epoch 250, training loss: 53.621483 , validation RMSE: 10.324198\n",
      "epoch 260, training loss: 44.446297 , validation RMSE: 9.433707\n",
      "epoch 270, training loss: 42.166237 , validation RMSE: 9.245086\n",
      "epoch 280, training loss: 41.249390 , validation RMSE: 9.182519\n",
      "epoch 290, training loss: 40.516743 , validation RMSE: 9.148515\n",
      "epoch 300, training loss: 39.892212 , validation RMSE: 9.131296\n",
      "epoch 310, training loss: 39.315910 , validation RMSE: 9.117414\n",
      "epoch 320, training loss: 38.626293 , validation RMSE: 9.101929\n",
      "epoch 330, training loss: 37.947048 , validation RMSE: 9.090546\n",
      "epoch 340, training loss: 37.216087 , validation RMSE: 9.086260\n",
      "epoch 350, training loss: 36.446861 , validation RMSE: 9.097033\n",
      "epoch 360, training loss: 35.514706 , validation RMSE: 9.091570\n",
      "epoch 370, training loss: 34.618530 , validation RMSE: 9.102730\n",
      "epoch 380, training loss: 33.732204 , validation RMSE: 9.140538\n",
      "epoch 390, training loss: 32.761440 , validation RMSE: 9.174665\n",
      "epoch 400, training loss: 31.625172 , validation RMSE: 9.189015\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  400\n"
     ]
    }
   ],
   "source": [
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "wd = 0.1\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 2e-4, 'wd': wd})\n",
    "model2.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824451 , validation RMSE: 10.921448\n",
      "epoch 20, training loss: 59.824326 , validation RMSE: 10.921435\n",
      "epoch 30, training loss: 59.824211 , validation RMSE: 10.921423\n",
      "epoch 40, training loss: 59.824100 , validation RMSE: 10.921412\n",
      "epoch 50, training loss: 59.823975 , validation RMSE: 10.921400\n",
      "epoch 60, training loss: 59.823818 , validation RMSE: 10.921385\n",
      "epoch 70, training loss: 59.823620 , validation RMSE: 10.921366\n",
      "epoch 80, training loss: 59.823364 , validation RMSE: 10.921340\n",
      "epoch 90, training loss: 59.823032 , validation RMSE: 10.921309\n",
      "epoch 100, training loss: 59.822586 , validation RMSE: 10.921266\n",
      "epoch 110, training loss: 59.821968 , validation RMSE: 10.921206\n",
      "epoch 120, training loss: 59.821075 , validation RMSE: 10.921121\n",
      "epoch 130, training loss: 59.819733 , validation RMSE: 10.920992\n",
      "epoch 140, training loss: 59.817612 , validation RMSE: 10.920791\n",
      "epoch 150, training loss: 59.814068 , validation RMSE: 10.920451\n",
      "epoch 160, training loss: 59.807674 , validation RMSE: 10.919844\n",
      "epoch 170, training loss: 59.794918 , validation RMSE: 10.918633\n",
      "epoch 180, training loss: 59.765568 , validation RMSE: 10.915856\n",
      "epoch 190, training loss: 59.682186 , validation RMSE: 10.907981\n",
      "epoch 200, training loss: 59.351086 , validation RMSE: 10.876697\n",
      "epoch 210, training loss: 57.379974 , validation RMSE: 10.689275\n",
      "epoch 220, training loss: 52.481255 , validation RMSE: 10.221041\n",
      "epoch 230, training loss: 44.968983 , validation RMSE: 9.477541\n",
      "epoch 240, training loss: 41.854446 , validation RMSE: 9.215717\n",
      "epoch 250, training loss: 40.856720 , validation RMSE: 9.167343\n",
      "epoch 260, training loss: 40.019264 , validation RMSE: 9.133547\n",
      "epoch 270, training loss: 39.234119 , validation RMSE: 9.120348\n",
      "epoch 280, training loss: 38.443409 , validation RMSE: 9.104574\n",
      "epoch 290, training loss: 37.602413 , validation RMSE: 9.098166\n",
      "epoch 300, training loss: 36.700974 , validation RMSE: 9.099787\n",
      "epoch 310, training loss: 35.635300 , validation RMSE: 9.113732\n",
      "epoch 320, training loss: 34.569763 , validation RMSE: 9.143641\n",
      "epoch 330, training loss: 33.476486 , validation RMSE: 9.193639\n",
      "epoch 340, training loss: 32.211552 , validation RMSE: 9.235149\n",
      "epoch 350, training loss: 30.979916 , validation RMSE: 9.279442\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  350\n"
     ]
    }
   ],
   "source": [
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),nn.Dense(45,activation='relu'),nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.01))\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "wd = 0.01\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 2e-4, 'wd': wd})\n",
    "model3.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|weight decay|validation RMSE|\n",
    "|----|----|\n",
    "|1|10.9214|\n",
    "|0.1|9.1890|\n",
    "|0.01|9.2794|\n",
    "\n",
    "從實驗結果得知，weight decay=0.1 的 validation RMSE最低，因此選用weight decay=0.1作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.311225891113281\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model2,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_dm_dropout\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 32,64,128 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.823814 , validation RMSE: 10.921388\n",
      "epoch 20, training loss: 59.822037 , validation RMSE: 10.921223\n",
      "epoch 30, training loss: 59.808613 , validation RMSE: 10.919962\n",
      "epoch 40, training loss: 58.588261 , validation RMSE: 10.804729\n",
      "epoch 50, training loss: 43.063652 , validation RMSE: 9.346679\n",
      "epoch 60, training loss: 39.862694 , validation RMSE: 9.152026\n",
      "epoch 70, training loss: 37.823639 , validation RMSE: 9.086305\n",
      "epoch 80, training loss: 35.823441 , validation RMSE: 9.076674\n",
      "epoch 90, training loss: 35.060814 , validation RMSE: 9.110268\n",
      "epoch 100, training loss: 33.458622 , validation RMSE: 9.121112\n",
      "epoch 110, training loss: 32.680523 , validation RMSE: 9.160365\n",
      "epoch 120, training loss: 31.453310 , validation RMSE: 9.150271\n",
      "epoch 130, training loss: 30.698637 , validation RMSE: 9.177656\n",
      "epoch 140, training loss: 30.231415 , validation RMSE: 9.224083\n",
      "epoch 150, training loss: 29.239084 , validation RMSE: 9.239199\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.0005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824188 , validation RMSE: 10.921421\n",
      "epoch 20, training loss: 59.823689 , validation RMSE: 10.921371\n",
      "epoch 30, training loss: 59.822861 , validation RMSE: 10.921292\n",
      "epoch 40, training loss: 59.821087 , validation RMSE: 10.921125\n",
      "epoch 50, training loss: 59.816257 , validation RMSE: 10.920669\n",
      "epoch 60, training loss: 59.797539 , validation RMSE: 10.918904\n",
      "epoch 70, training loss: 59.639805 , validation RMSE: 10.904027\n",
      "epoch 80, training loss: 52.514893 , validation RMSE: 10.216157\n",
      "epoch 90, training loss: 42.772877 , validation RMSE: 9.295037\n",
      "epoch 100, training loss: 41.333805 , validation RMSE: 9.216601\n",
      "epoch 110, training loss: 40.133137 , validation RMSE: 9.174685\n",
      "epoch 120, training loss: 39.071373 , validation RMSE: 9.131564\n",
      "epoch 130, training loss: 37.756714 , validation RMSE: 9.108133\n",
      "epoch 140, training loss: 36.945789 , validation RMSE: 9.102376\n",
      "epoch 150, training loss: 35.811268 , validation RMSE: 9.077980\n",
      "epoch 160, training loss: 35.075748 , validation RMSE: 9.097436\n",
      "epoch 170, training loss: 34.470478 , validation RMSE: 9.140828\n",
      "epoch 180, training loss: 33.801910 , validation RMSE: 9.138741\n",
      "epoch 190, training loss: 33.050301 , validation RMSE: 9.144341\n",
      "epoch 200, training loss: 32.418411 , validation RMSE: 9.163255\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  200\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.01))\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 0.0005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.824444 , validation RMSE: 10.921449\n",
      "epoch 20, training loss: 59.824295 , validation RMSE: 10.921433\n",
      "epoch 30, training loss: 59.824169 , validation RMSE: 10.921421\n",
      "epoch 40, training loss: 59.824032 , validation RMSE: 10.921408\n",
      "epoch 50, training loss: 59.823864 , validation RMSE: 10.921391\n",
      "epoch 60, training loss: 59.823643 , validation RMSE: 10.921371\n",
      "epoch 70, training loss: 59.823364 , validation RMSE: 10.921343\n",
      "epoch 80, training loss: 59.822948 , validation RMSE: 10.921305\n",
      "epoch 90, training loss: 59.822350 , validation RMSE: 10.921248\n",
      "epoch 100, training loss: 59.821449 , validation RMSE: 10.921164\n",
      "epoch 110, training loss: 59.819923 , validation RMSE: 10.921020\n",
      "epoch 120, training loss: 59.817261 , validation RMSE: 10.920769\n",
      "epoch 130, training loss: 59.812164 , validation RMSE: 10.920287\n",
      "epoch 140, training loss: 59.801361 , validation RMSE: 10.919272\n",
      "epoch 150, training loss: 59.773632 , validation RMSE: 10.916666\n",
      "epoch 160, training loss: 59.684486 , validation RMSE: 10.908286\n",
      "epoch 170, training loss: 59.241348 , validation RMSE: 10.866501\n",
      "epoch 180, training loss: 55.080845 , validation RMSE: 10.467981\n",
      "epoch 190, training loss: 45.788643 , validation RMSE: 9.561034\n",
      "epoch 200, training loss: 43.072800 , validation RMSE: 9.319849\n",
      "epoch 210, training loss: 42.122139 , validation RMSE: 9.252670\n",
      "epoch 220, training loss: 41.372818 , validation RMSE: 9.210772\n",
      "epoch 230, training loss: 40.704929 , validation RMSE: 9.171791\n",
      "epoch 240, training loss: 40.061386 , validation RMSE: 9.148382\n",
      "epoch 250, training loss: 39.318241 , validation RMSE: 9.126451\n",
      "epoch 260, training loss: 38.616684 , validation RMSE: 9.110807\n",
      "epoch 270, training loss: 37.943779 , validation RMSE: 9.092020\n",
      "epoch 280, training loss: 37.319569 , validation RMSE: 9.088221\n",
      "epoch 290, training loss: 36.843407 , validation RMSE: 9.088651\n",
      "epoch 300, training loss: 36.163330 , validation RMSE: 9.087624\n",
      "epoch 310, training loss: 35.538273 , validation RMSE: 9.077698\n",
      "epoch 320, training loss: 35.086308 , validation RMSE: 9.086166\n",
      "epoch 330, training loss: 34.521847 , validation RMSE: 9.091731\n",
      "epoch 340, training loss: 34.110699 , validation RMSE: 9.096495\n",
      "epoch 350, training loss: 33.499069 , validation RMSE: 9.106627\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  350\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model4 = nn.Sequential()\n",
    "model4.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model4.initialize(init.Normal(sigma=0.01))\n",
    "model4.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model4.collect_params(), 'sgd', {'learning_rate': 0.0005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model4,x_subtrain[:10000],y_subtrain_demean[:10000],x_val,y_val_demean,loss,trainer,num_epochs,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|32|9.2392|\n",
    "|64|9.1633|\n",
    "|128|9.1066|\n",
    "\n",
    "從實驗結果得知，batch size = 128 的 validation RMSE最低，因此選用batch size = 128作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.20824146270752\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model4,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_ykeep\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 16,32,64 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 59.825306 , validation RMSE: 10.921534\n",
      "epoch 20, training loss: 59.824612 , validation RMSE: 10.921453\n",
      "epoch 30, training loss: 59.828289 , validation RMSE: 10.921822\n",
      "epoch 40, training loss: 59.825462 , validation RMSE: 10.921523\n",
      "epoch 50, training loss: 59.826370 , validation RMSE: 10.921638\n",
      "epoch 60, training loss: 59.824806 , validation RMSE: 10.921469\n",
      "epoch 70, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 80, training loss: 59.827911 , validation RMSE: 10.921786\n",
      "epoch 90, training loss: 59.829426 , validation RMSE: 10.921870\n",
      "epoch 100, training loss: 59.830700 , validation RMSE: 10.921983\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  100\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.0005))\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 0.005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 721879367680.000000 , validation RMSE: 1201565.125000\n",
      "epoch 20, training loss: 59.848381 , validation RMSE: 10.923569\n",
      "epoch 30, training loss: 59.826138 , validation RMSE: 10.921581\n",
      "epoch 40, training loss: 59.824623 , validation RMSE: 10.921454\n",
      "epoch 50, training loss: 59.825649 , validation RMSE: 10.921569\n",
      "epoch 60, training loss: 59.825108 , validation RMSE: 10.921515\n",
      "epoch 70, training loss: 59.825092 , validation RMSE: 10.921514\n",
      "epoch 80, training loss: 59.824875 , validation RMSE: 10.921492\n",
      "epoch 90, training loss: 59.825207 , validation RMSE: 10.921524\n",
      "epoch 100, training loss: 59.824913 , validation RMSE: 10.921495\n",
      "epoch 110, training loss: 59.824417 , validation RMSE: 10.921440\n",
      "epoch 120, training loss: 59.825256 , validation RMSE: 10.921506\n",
      "epoch 130, training loss: 59.827732 , validation RMSE: 10.921720\n",
      "epoch 140, training loss: 59.824425 , validation RMSE: 10.921444\n",
      "epoch 150, training loss: 59.824905 , validation RMSE: 10.921476\n",
      "epoch 160, training loss: 59.824837 , validation RMSE: 10.921472\n",
      "epoch 170, training loss: 59.824726 , validation RMSE: 10.921462\n",
      "epoch 180, training loss: 59.824780 , validation RMSE: 10.921482\n",
      "epoch 190, training loss: 59.824818 , validation RMSE: 10.921486\n",
      "epoch 200, training loss: 59.824417 , validation RMSE: 10.921440\n",
      "epoch 210, training loss: 59.824856 , validation RMSE: 10.921472\n",
      "epoch 220, training loss: 59.825249 , validation RMSE: 10.921505\n",
      "epoch 230, training loss: 59.825130 , validation RMSE: 10.921495\n",
      "epoch 240, training loss: 59.824677 , validation RMSE: 10.921472\n",
      "epoch 250, training loss: 59.824451 , validation RMSE: 10.921447\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  250\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.0005))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 7744604.500000 , validation RMSE: 3935.636475\n",
      "epoch 20, training loss: 61.090042 , validation RMSE: 11.037183\n",
      "epoch 30, training loss: 59.824463 , validation RMSE: 10.921441\n",
      "epoch 40, training loss: 59.824520 , validation RMSE: 10.921454\n",
      "epoch 50, training loss: 59.824905 , validation RMSE: 10.921494\n",
      "epoch 60, training loss: 59.824417 , validation RMSE: 10.921443\n",
      "epoch 70, training loss: 59.824520 , validation RMSE: 10.921454\n",
      "epoch 80, training loss: 59.824417 , validation RMSE: 10.921440\n",
      "epoch 90, training loss: 59.824612 , validation RMSE: 10.921453\n",
      "epoch 100, training loss: 59.824638 , validation RMSE: 10.921467\n",
      "epoch 110, training loss: 59.824501 , validation RMSE: 10.921453\n",
      "epoch 120, training loss: 59.824471 , validation RMSE: 10.921449\n",
      "epoch 130, training loss: 59.824417 , validation RMSE: 10.921439\n",
      "epoch 140, training loss: 59.824642 , validation RMSE: 10.921454\n",
      "epoch 150, training loss: 59.824505 , validation RMSE: 10.921444\n",
      "epoch 160, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 170, training loss: 59.824455 , validation RMSE: 10.921447\n",
      "epoch 180, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 190, training loss: 59.824520 , validation RMSE: 10.921453\n",
      "epoch 200, training loss: 59.824417 , validation RMSE: 10.921443\n",
      "epoch 210, training loss: 59.824417 , validation RMSE: 10.921441\n",
      "epoch 220, training loss: 59.824425 , validation RMSE: 10.921439\n",
      "epoch 230, training loss: 59.824436 , validation RMSE: 10.921445\n",
      "epoch 240, training loss: 59.824455 , validation RMSE: 10.921441\n",
      "epoch 250, training loss: 59.824482 , validation RMSE: 10.921450\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  250\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.0005))\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 0.005})\n",
    "\n",
    "#train model\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|16|10.9220|\n",
    "|32|10.9214|\n",
    "|64|10.9215|\n",
    "\n",
    "從實驗結果得知，batch size = 32 的 validation RMSE最低，因此選用batch size = 32作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10.852547645568848\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model2,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_ykeep_L2\n",
    "**Tune Hyperparameter - weight decay** <br>\n",
    "try different weight decay = [0.1,0.05] and select the best weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 1882805248.000000 , validation RMSE: 61364.574219\n",
      "epoch 20, training loss: 356.574707 , validation RMSE: 26.700857\n",
      "epoch 30, training loss: 59.824482 , validation RMSE: 10.921451\n",
      "epoch 40, training loss: 59.824486 , validation RMSE: 10.921444\n",
      "epoch 50, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 60, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 70, training loss: 59.824417 , validation RMSE: 10.921443\n",
      "epoch 80, training loss: 59.824638 , validation RMSE: 10.921456\n",
      "epoch 90, training loss: 59.824417 , validation RMSE: 10.921442\n",
      "epoch 100, training loss: 59.824432 , validation RMSE: 10.921444\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  100\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.0002))\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "wd = 0.1\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 0.005,'wd':wd})\n",
    "model1.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model1,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 828402496.000000 , validation RMSE: 40703.875000\n",
      "epoch 20, training loss: 190.613693 , validation RMSE: 19.518221\n",
      "epoch 30, training loss: 59.824444 , validation RMSE: 10.921440\n",
      "epoch 40, training loss: 59.824608 , validation RMSE: 10.921463\n",
      "epoch 50, training loss: 59.824417 , validation RMSE: 10.921439\n",
      "epoch 60, training loss: 59.824436 , validation RMSE: 10.921445\n",
      "epoch 70, training loss: 59.824661 , validation RMSE: 10.921457\n",
      "epoch 80, training loss: 59.824471 , validation RMSE: 10.921449\n",
      "epoch 90, training loss: 59.824593 , validation RMSE: 10.921462\n",
      "epoch 100, training loss: 59.824455 , validation RMSE: 10.921447\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  100\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.0002))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "wd = 0.05\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.005,'wd':wd})\n",
    "model2.collect_params('.*bias').setattr('wd_mult', 0)\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model2,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|weight decay|validation RMSE|\n",
    "|----|----|\n",
    "|0.05|10.921444|\n",
    "|0.1|10.921447|\n",
    "\n",
    "從實驗結果得知，weight decay = 0.1 的 validation RMSE最低，因此選用weight decay = 0.1作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10.852538108825684\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model2,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_ykeep_dropout\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 64,128 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 952378898757189632.000000 , validation RMSE: 1380129792.000000\n",
      "epoch 20, training loss: 149953789952.000000 , validation RMSE: 547638.187500\n",
      "epoch 30, training loss: 23667.128906 , validation RMSE: 217.566757\n",
      "epoch 40, training loss: 59.827457 , validation RMSE: 10.921741\n",
      "epoch 50, training loss: 59.824520 , validation RMSE: 10.921453\n",
      "epoch 60, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 70, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 80, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 90, training loss: 59.824512 , validation RMSE: 10.921446\n",
      "epoch 100, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 110, training loss: 59.824486 , validation RMSE: 10.921444\n",
      "epoch 120, training loss: 59.824474 , validation RMSE: 10.921450\n",
      "epoch 130, training loss: 59.824455 , validation RMSE: 10.921440\n",
      "epoch 140, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 150, training loss: 59.824493 , validation RMSE: 10.921451\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "model3 = nn.Sequential()\n",
    "model3.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model3.initialize(init.Normal(sigma=0.005))\n",
    "model3.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model3.collect_params(), 'sgd', {'learning_rate': 0.005})\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model3,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 1663326413063255490560.000000 , validation RMSE: 57677144064.000000\n",
      "epoch 20, training loss: 660012640898121728.000000 , validation RMSE: 1148923520.000000\n",
      "epoch 30, training loss: 261894791233536.000000 , validation RMSE: 22886450.000000\n",
      "epoch 40, training loss: 103920574464.000000 , validation RMSE: 455895.937500\n",
      "epoch 50, training loss: 41236160.000000 , validation RMSE: 9081.430664\n",
      "epoch 60, training loss: 16422.419922 , validation RMSE: 181.233658\n",
      "epoch 70, training loss: 66.318138 , validation RMSE: 11.501677\n",
      "epoch 80, training loss: 59.826588 , validation RMSE: 10.921659\n",
      "epoch 90, training loss: 59.824425 , validation RMSE: 10.921440\n",
      "epoch 100, training loss: 59.824417 , validation RMSE: 10.921439\n",
      "epoch 110, training loss: 59.824413 , validation RMSE: 10.921441\n",
      "epoch 120, training loss: 59.824413 , validation RMSE: 10.921439\n",
      "epoch 130, training loss: 59.824413 , validation RMSE: 10.921440\n",
      "epoch 140, training loss: 59.824425 , validation RMSE: 10.921443\n",
      "epoch 150, training loss: 59.824417 , validation RMSE: 10.921439\n",
      "------Early Stop------\n",
      "finish training... End at Epoch  150\n"
     ]
    }
   ],
   "source": [
    "model4 = nn.Sequential()\n",
    "model4.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model4.initialize(init.Normal(sigma=0.005))\n",
    "model4.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model4.collect_params(), 'sgd', {'learning_rate': 0.005})\n",
    "\n",
    "num_epochs = 3000\n",
    "train_model(model4,x_subtrain[:10000],y_subtrain[:10000],x_val,y_val,loss,trainer,num_epochs,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|64|10.9215|\n",
    "|128|10.9214|\n",
    "\n",
    "從實驗結果得知，batch size = 128 的 validation RMSE最低，因此選用batch size = 128作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10.852678298950195\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model4,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP_2_dm_dropout_full\n",
    "**Tune Hyperparameter - batch size** <br>\n",
    "try different batch size = 256,512 and select the best batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 38.769062 , validation RMSE: 8.782681\n",
      "epoch 20, training loss: 38.647022 , validation RMSE: 8.780467\n",
      "epoch 30, training loss: 38.447243 , validation RMSE: 8.764668\n",
      "epoch 40, training loss: 38.209610 , validation RMSE: 8.746068\n",
      "epoch 50, training loss: 37.873760 , validation RMSE: 8.707487\n",
      "finish training... End at Epoch  50\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model1 = nn.Sequential()\n",
    "model1.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model1.initialize(init.Normal(sigma=0.01))\n",
    "model1.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model1.collect_params(), 'sgd', {'learning_rate': 0.01})\n",
    "\n",
    "num_epochs = 50\n",
    "train_model(model1,x_subtrain,y_subtrain_demean,x_val,y_val_demean,loss,trainer,num_epochs,batch_size=256,early_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss: 38.663067 , validation RMSE: 8.753753\n",
      "epoch 20, training loss: 38.327370 , validation RMSE: 8.732924\n",
      "epoch 30, training loss: 38.236294 , validation RMSE: 8.737166\n",
      "epoch 40, training loss: 38.118820 , validation RMSE: 8.723217\n",
      "epoch 50, training loss: 37.967419 , validation RMSE: 8.715676\n",
      "finish training... End at Epoch  50\n"
     ]
    }
   ],
   "source": [
    "# model structure\n",
    "model2 = nn.Sequential()\n",
    "model2.add(nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(45,activation='relu'),\n",
    "          nn.Dropout(0.5),\n",
    "          nn.Dense(1))\n",
    "model2.initialize(init.Normal(sigma=0.01))\n",
    "model2.collect_params().reset_ctx(gpu())\n",
    "\n",
    "# Loss\n",
    "loss = gluon.loss.L2Loss()\n",
    "\n",
    "#trainer\n",
    "trainer = gluon.Trainer(model2.collect_params(), 'sgd', {'learning_rate': 0.01})\n",
    "\n",
    "#\n",
    "num_epochs = 50\n",
    "train_model(model2,x_subtrain,y_subtrain_demean,x_val,y_val_demean,loss,trainer,num_epochs,batch_size=512,early_stop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|batch size|validation RMSE|\n",
    "|----|----|\n",
    "|256|8.7075|\n",
    "|512|8.7157|\n",
    "\n",
    "從實驗結果得知，batch size = 256 的 validation RMSE最低，因此選用batch size = 256作為最佳模型，並用test data算出最佳模型的RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 8.868842124938965\n"
     ]
    }
   ],
   "source": [
    "evaluate_RMSE(model1,x_test,y_test_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "Summarize test RMSE in one table. Discuss your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Case|Test RMSE|\n",
    "|----|----|\n",
    "|OLS|9.5507|\n",
    "|MLP_0_dm|9.5488|\n",
    "|MLP_1_dm|9.2210|\n",
    "|MLP_2_dm|9.1779|\n",
    "|MLP_2_dm_L2|9.3112|\n",
    "|MLP_2_dm_dropout|9.2082|\n",
    "|MLP_2_ykeep|10.8525|\n",
    "|MLP_2_ykeep_L2|10.8525|\n",
    "|MLP_2_ykeep_dropout|10.8527|\n",
    "|MLP_2_dm_dropout_full|8.8688|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們使用test RMSE評估各種模型的成效，RMSE越低表示模型成效越好。\n",
    "\n",
    "OLS和MLP_0_dm都是Linear Regression，差異在於MLP_0_dm找模型最佳解的方式，使用gradient descent，兩者的模型成效差異不大，MLP_0_dm略佳。<br>\n",
    "\n",
    "以MLP模型layer數多寡來看，MLP_0_dm多加一層hidden layer變成MLP_1_dm，模型的成效提升，可見多加一層是比較好的。但若再加一層hidden layer變成MLP_2_dm，雖然模型的成效還是有提升，卻比較容易有Overfitting的問題。\n",
    "\n",
    "由於MLP_2_dm容易有Overfitting的問題，所以嘗試兩種解決Overfitting的方式 - L2 Regularization and Dropout。我發現MLP_2_dm_dropout比MLP_2_dm_L2的模型成效還要好，有可能是在L2還沒有tune到更好的weight decay，又或是在這個資料上，使用dropout比使用L2 Regularization還要好\n",
    "\n",
    "至於在資料上事先對y做de-mean，對MLP模型成效會有甚麼影響。我發現沒有做de-mean所訓練的模型，在訓練初期會有比較大的training loss，在給定初始模型weight上要特別設定，初始的weight不要太大，不然容易有loss過大降不下來的情形發生。除此之外，沒做de-mean的話比較容易讓training loss卡在local minima，就不像有對資料做de-mean的模型，可以讓training loss和validation RMSE再下降。對沒做de-mean的模型而言，有沒有做L2 regularization和dropout並不太影響模型成效。\n",
    "\n",
    "最後，可以從MLP_2_dm_dropout_full得知，當訓練資料變多時，事先對y做de-mean，採用兩層hidden layer(MLP_2)並使用Dropout的MLP模型，其模型成效比前面所有的Case model都還要好(Test RMSE最小)。可見在這個Dataset上，訓練資料比較多，MLP模型自然也會表現得比較好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
